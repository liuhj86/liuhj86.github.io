<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Hongji  Liu</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.">

  <!-- Open Graph -->


  <!-- Bootstrap & MDB -->
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

  <!-- Code Syntax Highlighting -->
  <link rel="stylesheet" href="{ site.highlight_theme }" />

  <!-- Styles -->

  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>➿</text></svg>">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/">

  <!-- JQuery -->
  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


  <!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <script src="/assets/js/dark_mode.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-3G1BFNQMM9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-3G1BFNQMM9');
  </script>




    
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


</head>

<body class="fixed-top-nav ">

    <!-- Header -->

  <header>
    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
      <div class="container"> 
            <!-- Social Icons -->
        <div class="navbar-brand social">
            <!-- <a href="mailto:%70%63%61%69%61%61@%63%6F%6E%6E%65%63%74.%75%73%74.%68%6B"><i class="fas fa-envelope"></i></a> -->
            <a href="mailto:hliucq@connect.ust.hk"><i class="fas fa-envelope"></i></a>
            <a href="https://orcid.org/0000-0003-0272-3045" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
            <a href="https://scholar.google.com/citations?hl=zh-CN&user=Rsp3NIEAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
            <a href="https://www.researchgate.net/profile/Hongji-Liu-5/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
            <a href="https://github.com/liuhj86" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
            <a href="/assets/pdf/Hongji_Liu_Research_CV_202404.pdf" target="_blank" title="CV"><i class="ai ai-cv"></i></a>
        </div>
          
        <!-- Navbar Toggle -->
        <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar top-bar"></span>
          <span class="icon-bar middle-bar"></span>
          <span class="icon-bar bottom-bar"></span>
        </button>
        <div class="collapse navbar-collapse text-right" id="navbarNav">
          <ul class="navbar-nav ml-auto flex-nowrap">
            <!-- About -->
            <li class="nav-item ">
              <a class="nav-link" href="/">
                Home
                
                  <span class="sr-only">(current)</span>
              </a>
            </li>
            <!-- Other pages -->
            <li class="nav-item ">
                <!-- <a class="nav-link" href="/publications/">
                  Publications
                
                </a> -->
            </li>
            
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
              
          </ul>
        </div>
      </div>
    </nav>
  </header>


  <!-- Content -->

  <div class="container mt-5">
    <div class="post">

      <header class="post-header">
        <h1 class="post-title">
        <span class="font-weight-bold">Hongji</span>  Liu
        </h1>
        <p class="desc"><small>Ph.D. candidate in Robotics and Autonomous Systems, HKUST</small></p>
      </header>

      <article>
        <div class="profile float-right">
            <img class="img-fluid z-depth-1 rounded" src="/assets/img/lhj_2024.jpg">
        </div>
        <div class="clearfix">
          <p>
            I am a Ph.D. candidate from <a href="https://www.ust.hk/">The Hong Kong Univerisity of Science and Technology</a>
            at the <a href="https://personal.hkust-gz.edu.cn/junma/index.html">Robot Motion Planning and Control Lab</a> 
            under the supervison of <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/MA-Jun/eejma">Prof. Jun Ma</a>, and also at the
            <a href="https://www.ram-lab.com/">Robotics and Multi-perception Lab</a> in <a href="http://ri.ust.hk/">Robotics Institute</a>, 
            under the supervision of Prof. Ming Liu and <a href="https://cqf.io/">Prof. Qifeng Chen</a>. 
            I received my bachelor's degree in Software Engineering from <a href="https://www.sysu.edu.cn/">Sun Yat-sen University</a> in 2019.
          </p>

          <p>
            My research interests mainly include high-definition maps, semantic mapping, robot state estimation, and 
            SLAM (Simultaneous Localization and Mapping), mainly applied to autonomous driving and robotics.
          </p>

          <p>
            <em>Maps</em> play a key role in indoor robots, autonomous vehicles and other robotics derived applications. 
            Maps with complete functions, easy storage and high accuracy are very important for robot perception, localization and planning. 
            Therefore, I am devoted to exploring efficient and accurate map expression forms applicable to robots in different application scenarios and tasks.
             It is expected to take the map as the link to help improve the performance of the robot in different application scenarios.
          </p>
        </div>
        <!-- <hr> -->
        <!-- News -->
        <!-- <div class="news mt-3 p-0">
          <h3 class="title mb-4 p-0">News</h3> -->
          <!--div class="row p-0">
            <div class="col-sm-2 p-0">
              <span class="badge danger-color-dark darken-1 font-weight-bold text-uppercase align-middle date ml-3">
                Jul 1, 2021
              </span>
            </div>
            <div class="col-sm-10 mt-2 mt-sm-0 ml-3 ml-md-0 p-0 font-weight-light text">
              <p>Our work on <a href="https://arxiv.org/pdf/2107.08325">“Vision-based Autonomous Car Racing Using Deep Imitative Reinforcement Learning”</a> is accepted by RA-L &amp; IROS 2021.</p>
            </div>
          </div>
        
          <div class="row p-0">
            <div class="col-sm-2 p-0">
              <span class="badge danger-color-dark darken-1 font-weight-bold text-uppercase align-middle date ml-3">
                Jul 1, 2021
              </span>
            </div>
            <div class="col-sm-10 mt-2 mt-sm-0 ml-3 ml-md-0 p-0 font-weight-light text">
              <p>Our work on <a href="https://arxiv.org/pdf/2011.06775.pdf">“Learning Scalable Self-Driving Policies for Generic Traffic Scenarios with Graph Neural Networks”</a> is accepted by IROS 2021.</p>
            </div>
          </div>
        
          <div class="row p-0">
            <div class="col-sm-2 p-0">
              <span class="badge danger-color-dark darken-1 font-weight-bold text-uppercase align-middle date ml-3">
                Apr 1, 2021
              </span>
            </div>
            <div class="col-sm-10 mt-2 mt-sm-0 ml-3 ml-md-0 p-0 font-weight-light text">
              <p>Successful end to the first <em>HKUST-Kaisa Autonomous RC Car Racing Competition</em> (25 teams, 90+ participants). <a href="https://www.ec.ust.hk/news/successful-end-first-hkust-kaisa-autonomous-rc-car-racing-competition-great-support-kaisa">[News]</a> &amp; <a href="https://github.com/caipeide/autorace">[Code]</a> &amp; <a href="https://drive.google.com/file/d/1r3IwP727UHhTRmrFhijQqkteZpSrXvzW/view?usp=sharing">[Video]</a>. I am the PI of this project.</p>
            </div>
          </div-->
        <!-- </div> -->
        <hr>
          
        <!-- Publication -->

        <div class="publications mt-3 p-0">
          <h3 class="title mb-4 p-0">Selected publications</h3>
          <ol class="bibliography">

            <li>
              <div class="row">
                <div class="col-sm-3">
                  <img class="img-fluid" src="/assets/pubimg/dq-gat.png">
                </div>
                <div id="E-IPM" class="col-sm-8">
            
                  <div class="title">Enhance Inverse Perspective Mapping for Automatic Vectorized Road Map Generation</div>
                  <div class="author">
                    <em>Hongji Liu</em>,
                    Linwei Zheng,
                    Yongjian Li,
                    Mingkai Tang,
                    Xiaoyang Yan,
                    and <a href="https://personal.hkust-gz.edu.cn/junma/index.html"
                      target="_blank">Jun Ma</a>
                  </div>
            
                  <div class="periodical">
                    <em>Under Review</em>
                    , 2025
                  </div>
            
            
                  <div class="links">
            
                    <!-- <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a> -->
            
                    <!-- <a href="https://ieeexplore.ieee.org/document/10497895" class="badge grey waves-effect font-weight-light mr-1"
                      role="button" target="_blank">PDF</a> -->
            
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Cite</a> -->
            
                    <!-- <a href="/VHDMap-SE/" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Website</a> -->
            
                  </div>
            
                  <div class="abstract hidden">
                    <p>As unmanned ground vehicles (UGVs) applications expand to 
                      large-scale and open road scenarios, vectorized high-definition 
                      maps (VHD maps) demonstrate greater potential in solving state
                       correction problems than traditional metric maps. Previous 
                       related studies typically employ proprietary versions of VHD 
                       maps without fully leveraging the common traffic elements' 
                       information. In addition, there is a lack of research on 
                       efficient interaction methods between UGVs and VHD maps. To 
                       fill these gaps, we propose a universal UGV state estimation 
                       system and a query-based VHD map data exchange protocol. The 
                       system utilizes VHD maps to correct the lateral and longitudinal
                        positions as well as the yaw orientation of UGVs. The data 
                        exchange protocol enables UGVs to obtain real-time VHD map 
                        information and process it efficiently. To ensure universality, 
                        we accommodate two widely used VHD map formats, ASAM OpenDRIVE
                         and Apollo OpenDRIVE and provide corresponding map parsing 
                         methods. The evaluation of the system is conducted both in 
                         simulated and real-world scenes. In the simulation experiments,
                          we fully measure the effectiveness and accuracy of our method,
                           as well as its sensitivity to measurement noise. 
                           In real-world experiments, we compare the state estimation
                            accuracy of our system with SOTA simultaneous localization
                             and mapping methods on an open road. The results show that
                              our system demonstrates better accuracy than other 
                              baselines on most data sequences. The proposed map data
                               exchange protocol meets real-time requirements. For the
                                community's reference, the system code is available at
                                 https://github.com/liuhj86/VHDMap-SE.
                    </p>
                  </div>
                </div>
              </div>
            </li>





            <li>
              <div class="row">
                <div class="col-sm-3">
                  <img class="img-fluid" src="/VHDMap-SE/simulation_construction.png">
                </div>
                <div id="VHDMap-SE" class="col-sm-8">
            
                  <div class="title">VHDMap-SE: A Universal Vectorized High-definition Map Aided Vehicle State Estimator</div>
                  <div class="author">
                    <em>Hongji Liu</em>,
                    Mingkai Tang,
                    Mingkai Jia,
                    Yingbing Chen,
                    <a href="https://zarathustr.github.io/"
                      target="_blank">Jin Wu</a>
                    and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium"
                      target="_blank">Ming Liu</a>
                  </div>
            
                  <div class="periodical">
                    <em>IEEE Transactions on Intelligent Vehicles (T-IV)</em>
                    , 2024
                  </div>
            
            
                  <div class="links">
            
                    <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>
            
                    <a href="https://ieeexplore.ieee.org/document/10497895" class="badge grey waves-effect font-weight-light mr-1"
                      role="button" target="_blank">PDF</a>
            
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Cite</a> -->
            
                    <a href="/VHDMap-SE/" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Website</a>
            
                  </div>
            
                  <div class="abstract hidden">
                    <p>As unmanned ground vehicles (UGVs) applications expand to 
                      large-scale and open road scenarios, vectorized high-definition 
                      maps (VHD maps) demonstrate greater potential in solving state
                       correction problems than traditional metric maps. Previous 
                       related studies typically employ proprietary versions of VHD 
                       maps without fully leveraging the common traffic elements' 
                       information. In addition, there is a lack of research on 
                       efficient interaction methods between UGVs and VHD maps. To 
                       fill these gaps, we propose a universal UGV state estimation 
                       system and a query-based VHD map data exchange protocol. The 
                       system utilizes VHD maps to correct the lateral and longitudinal
                        positions as well as the yaw orientation of UGVs. The data 
                        exchange protocol enables UGVs to obtain real-time VHD map 
                        information and process it efficiently. To ensure universality, 
                        we accommodate two widely used VHD map formats, ASAM OpenDRIVE
                         and Apollo OpenDRIVE and provide corresponding map parsing 
                         methods. The evaluation of the system is conducted both in 
                         simulated and real-world scenes. In the simulation experiments,
                          we fully measure the effectiveness and accuracy of our method,
                           as well as its sensitivity to measurement noise. 
                           In real-world experiments, we compare the state estimation
                            accuracy of our system with SOTA simultaneous localization
                             and mapping methods on an open road. The results show that
                              our system demonstrates better accuracy than other 
                              baselines on most data sequences. The proposed map data
                               exchange protocol meets real-time requirements. For the
                                community's reference, the system code is available at
                                 https://github.com/liuhj86/VHDMap-SE.
                    </p>
                  </div>
                </div>
              </div>
            </li>


            <li>
              <div class="row">
                <div class="col-sm-3">
                  <img class="img-fluid" src="/PGO-IPM/pics/scene.png">
                </div>
                <div id="PGO-IPM" class="col-sm-8">
            
                  <div class="title">PGO-IPM: Enhance IPM Accuracy with Pose-guided Optimization for Low-cost High-definition Angular Marking Map Generation</div>
                  <div class="author">
                    <em>Hongji Liu</em>,
                    Linwei Zheng,
                    Xiaoyang Yan,
                    Zhenhua Xu,
                    Bohuan Xue,
                    Yang Yu,
                    <!-- <a href="https://hlwang1124.github.io/" target="_blank">Hengli Wang</a>,
                    <a href="https://www.polyu.edu.hk/me/people/academic-teaching-staff/sun-yuxiang-dr/" target="_blank">Yuxiang
                      Sun</a>, -->
                    and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium"
                      target="_blank">Ming Liu</a>
                  </div>
            
                  <div class="periodical">
                    <em>35th IEEE Intelligent Vehicles Symposium (IV)</em>
                    , 2024
                  </div>
            
            
                  <div class="links">
            
                    <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>
            
                    <a href="https://arxiv.org/pdf/2209.07737.pdf" class="badge grey waves-effect font-weight-light mr-1"
                      role="button" target="_blank">PDF</a>
            
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Cite</a> -->
            
                    <a href="/PGO-IPM" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Website</a>
            
                  </div>
            
                  <div class="abstract hidden">
                    <p>High-definition angular marking maps (HDAM maps) are vital in large-scale environments with variable appearances. In
                    these scenarios, unmanned ground vehicles (UGVs) can use angular markings for localization because they are easy to
                    identify and informative for localization. However, creating such a marking map relies heavily on manual measurement and
                    annotation, which is time-consuming and laborious. Although Inverse Perspective Mapping (IPM) offers a low-cost and
                    automated alternative, its accuracy is compromised by vehicle motion and the arduous pre-calibration of the IPM matrix.
                    To fill these gaps, we propose a pose-guided optimization framework for IPM. This framework enables the automated
                    generation of HDAM maps, while concurrently refining the preliminary IPM matrix. We deployed the proposed method in two
                    different automated ports, and the method yielded HDAM maps with near-centimeter precision. Moreover, the refined IPM
                    matrix matched the accuracy of manual calibrations. The supplementary materials and videos are available at
                    http://liuhongji.site/PGO-IPM/.
                    </p>
                  </div>
                </div>
              </div>
            </li>
            

            <li>
              <div class="row">
                <div class="col-sm-3">
                  <img class="img-fluid" src="/360ST-Mapping/pics/teaser.png">
                </div>
                <div id="360ST-Mapping" class="col-sm-8">
              
                  <div class="title">360ST-Mapping: An Online Semantics-Guided Topological Mapping Module for Omnidirectional Visual SLAM</div>
                  <div class="author">
                    <em>Hongji Liu</em>,
                    <a href="https://huajianup.github.io/" target="_blank">Huajian Huang</a>,
                    <a href="https://www.saikit.org/" target="_blank">Sai-Kit Yeung</a>,
                  
                    and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium" target="_blank">Ming Liu</a>
                  </div>

                  <div class="periodical">
                    <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS​)</em>
                    , 2022
                  </div>
              

                  <div class="links">
              
                  <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>
              
                  <a href="https://ieeexplore.ieee.org/document/9982142" class="badge grey waves-effect font-weight-light mr-1"
                   role="button" target="_blank">PDF</a>
                    
                  <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Cite</a> -->
                  
                  <a href="/360ST-Mapping" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Website</a>
                
                  </div>
                  
                  <div class="abstract hidden">
                    <p>Topological map as an abstract representation of the observed environment has the advantage in path planning
                       and navigation. Here we proposed an online topological mapping method, 360ST-Mapping, by making use of 
                       omnidirectional vision. The 360° field of view allows the agent to obtain consistent observation and incrementally
                        extract topological environment information. Moreover, we leverage semantic information to guide topological
                         places recognition further improving performance. The topological map possessing semantic information has the
                          potential to support semantics-related advanced tasks. After combining the topological mapping module with the 
                          omnidirectional visual SLAM, we conduct extensive experiments in several large-scale indoor scenes to validate 
                          the effectiveness.</p>
                  </div>
                </div>
              </div>
            </li>
          </ol>

        </div>
        <a href="/publications">SEE ALL PUBLICATIONS</a>
        <hr>

        <!--div class="publications mt-3 p-0">
          <h3 class="title mb-4 p-0">Service</h3>
          Reviewer for IEEE Robotics and Automation Letters (RA-L)
          <br>Reviewer for IEEE International Conference on Robotics and Automation (ICRA)
          <br>Reviewer for IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
        </div>

        <hr-->
        <div class="social">
          <div class="contact-icons">
            <!-- <a href="mailto:%70%63%61%69%61%61@%63%6F%6E%6E%65%63%74.%75%73%74.%68%6B"><i class="fas fa-envelope"></i></a>
            <a href="https://orcid.org/0000-0002-9759-2991" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
            <a href="https://scholar.google.com/citations?user=D4YzMA8AAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
            <a href="https://www.researchgate.net/profile/Peide-Cai/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
            <a href="https://github.com/caipeide" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
            <a href="/assets/pdf/resume_cpd.pdf" target="_blank" title="CV"><i class="ai ai-cv"></i></a>-->
            <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=t&d=rs_QRxbRIrOrbxz4PSnFQx4NmTFzd148ECINh5VkHJU&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
          </div>
          <div class="contact-note"></div>
        </div>
      </article>
    </div>
  </div>

  <!-- Footer -->
    
  <footer class="fixed-bottom">
    <div class="container mt-0">
      &copy; Copyright 2022 Hongji  Liu.
      Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.      
      Last updated: April 14, 2024.
    </div>
  </footer>
</body>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
