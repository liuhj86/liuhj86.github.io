<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Hongji  Liu | Publications</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="{ site.highlight_theme }" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üç™</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3G1BFNQMM9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-3G1BFNQMM9');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://liuhj86.github.io/">
       <span class="font-weight-bold">Hongji</span>   Liu
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              Home
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

<div class="container mt-5">
  <div class="post">

    <header class="post-header">
      <h1 class="post-title">Publications</h1>
      <p class="post-description"><em>*</em> denotes equal contribution.</p>
    </header>

    <article>
      <div class="publications">


        <h2 class="year">2024</h2>
        <ol class="bibliography">
          <li>
            <div class="row">
  <!-- <div class="col-sm-2 abbr">
    <abbr class="badge">dq-gat</abbr>  
  </div> -->
              <div class="col-sm-3">
              
                <img class="img-fluid" src="/VHDMap-SE/simulation_construction.png" />
              
              </div>

              <div id="VHDMap-SE" class="col-sm-8">
                
                <div class="title">VHDMap-SE: A Universal Vectorized High-definition Map Aided Vehicle State Estimator</div>
                  <div class="author">
                
                    <em>Hongji Liu</em>,
                        Mingkai Tang,
                        Mingkai Jia,
                        Yingbing Chen,
                        <a href="https://zarathustr.github.io/"
                          target="_blank">Jin Wu</a>
                        and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium"
                          target="_blank">Ming Liu</a>
                    
                  
                  </div>

                  <div class="periodical">
                    <em>IEEE Transactions on Intelligent Vehicles (T-IV)</em>
                        , 2024
                  </div>
            

                  <div class="links">
                    <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>        
                    <a href="https://ieeexplore.ieee.org/document/10497895" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">PDF</a>
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Cite</a> -->
                    <!-- <a href="/dq-gat" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Website</a> -->
                  </div>

                  <!-- Hidden abstract block -->
                  
                  <div class="abstract hidden">
                    <p>As unmanned ground vehicles (UGVs) applications expand to 
                      large-scale and open road scenarios, vectorized high-definition 
                      maps (VHD maps) demonstrate greater potential in solving state 
                      correction problems than traditional metric maps. Previous 
                      related studies typically employ proprietary versions of VHD 
                      maps without fully leveraging the common traffic elements' 
                      information. In addition, there is a lack of research on 
                      efficient interaction methods between UGVs and VHD maps. To 
                      fill these gaps, we propose a universal UGV state estimation 
                      system and a query-based VHD map data exchange protocol. The 
                      system utilizes VHD maps to correct the lateral and longitudinal 
                      positions as well as the yaw orientation of UGVs. The data 
                      exchange protocol enables UGVs to obtain real-time VHD map 
                      information and process it efficiently. To ensure universality, 
                      we accommodate two widely used VHD map formats, ASAM OpenDRIVE 
                      and Apollo OpenDRIVE and provide corresponding map parsing 
                      methods. The evaluation of the system is conducted both in 
                      simulated and real-world scenes. In the simulation experiments, 
                      we fully measure the effectiveness and accuracy of our method, 
                      as well as its sensitivity to measurement noise. In real-world 
                      experiments, we compare the state estimation accuracy of our 
                      system with SOTA simultaneous localization and mapping methods 
                      on an open road. The results show that our system demonstrates 
                      better accuracy than other baselines on most data sequences. 
                      The proposed map data exchange protocol meets real-time 
                      requirements. For the community's reference, the system code is 
                      available at https://github.com/liuhj86/VHDMap-SE.
                    </p>
                  </div>
                </div>
              </div>
          </li>


          <li>
              <div class="row">
                <div class="col-sm-3">
                  <img class="img-fluid" src="/PGO-IPM/pics/scene.png">
                </div>
                <div id="PGO-IPM" class="col-sm-8">
            
                  <div class="title">PGO-IPM: Enhance IPM Accuracy with Pose-guided Optimization for Low-cost High-definition Angular Marking Map Generation</div>
                  <div class="author">
                    <em>Hongji Liu</em>,
                    Linwei Zheng,
                    Xiaoyang Yan,
                    Zhenhua Xu,
                    Bohuan Xue,
                    Yang Yu,
                    <!-- <a href="https://hlwang1124.github.io/" target="_blank">Hengli Wang</a>,
                    <a href="https://www.polyu.edu.hk/me/people/academic-teaching-staff/sun-yuxiang-dr/" target="_blank">Yuxiang
                      Sun</a>, -->
                    and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium"
                      target="_blank">Ming Liu</a>
                  </div>
            
                  <div class="periodical">
                    <em>35th IEEE Intelligent Vehicles Symposium (IV)</em>
                    , 2024
                  </div>
            
            
                  <div class="links">
            
                    <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>
            
                    <a href="https://arxiv.org/pdf/2209.07737.pdf" class="badge grey waves-effect font-weight-light mr-1"
                      role="button" target="_blank">PDF</a>
            
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Cite</a> -->
            
                    <a href="/PGO-IPM" class="badge grey waves-effect font-weight-light mr-1" role="button"
                      target="_blank">Website</a>
            
                  </div>
            
                  <div class="abstract hidden">
                    <p>High-definition angular marking maps (HDAM maps) are vital in large-scale environments with variable appearances. In
                    these scenarios, unmanned ground vehicles (UGVs) can use angular markings for localization because they are easy to
                    identify and informative for localization. However, creating such a marking map relies heavily on manual measurement and
                    annotation, which is time-consuming and laborious. Although Inverse Perspective Mapping (IPM) offers a low-cost and
                    automated alternative, its accuracy is compromised by vehicle motion and the arduous pre-calibration of the IPM matrix.
                    To fill these gaps, we propose a pose-guided optimization framework for IPM. This framework enables the automated
                    generation of HDAM maps, while concurrently refining the preliminary IPM matrix. We deployed the proposed method in two
                    different automated ports, and the method yielded HDAM maps with near-centimeter precision. Moreover, the refined IPM
                    matrix matched the accuracy of manual calibrations. The supplementary materials and videos are available at
                    http://liuhongji.site/PGO-IPM/.
                    </p>
                  </div>
                </div>
              </div>
          </li>


          <li>
            <div class="row">
  <!-- <div class="col-sm-2 abbr">
    <abbr class="badge">dq-gat</abbr>  
  </div> -->
              <div class="col-sm-3">
              
                <img class="img-fluid" src="/DHP-Mapping/main_pic-1.png" />
              
              </div>

              <div id="DHP-Mapping" class="col-sm-8">
                
                <div class="title">DHP-Mapping: A Dense Panoptic Mapping System with Hierarchical World Representation and Label Optimization Techniques</div>
                  <div class="author">
                        Tianshuai Hu,
                        <a href="https://gogojjh.github.io/"
                          target="_blank">Jianhao Jiao</a>,
                        Yucheng Xu,
                    <em>Hongji Liu</em>,
                        Sheng Wang,
                        and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium"
                          target="_blank">Ming Liu</a>
                    
                  
                  </div>

                  <div class="periodical">
                    <em>Under Review</em>
                        , 2024
                  </div>
            

                  <div class="links">
                    <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>        
                    <a href="https://arxiv.org/pdf/2403.16880.pdf" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">PDF</a>
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Cite</a> -->
                    <!-- <a href="/dq-gat" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Website</a> -->
                  </div>

                  <!-- Hidden abstract block -->
                  
                  <div class="abstract hidden">
                    <p>Maps provide robots with crucial environmental knowledge, thereby 
                      enabling them to perform interactive tasks effectively. Easily 
                      accessing accurate abstract-to-detailed geometric and semantic 
                      concepts from maps is crucial for robots to make informed and 
                      efficient decisions. To comprehensively model the environment 
                      and effectively manage the map data structure, we propose 
                      DHP-Mapping, a dense mapping system that utilizes multiple 
                      Truncated Signed Distance Field (TSDF) submaps and panoptic labels 
                      to hierarchically model the environment. The output map is able to 
                      maintain both voxel- and submap-level metric and semantic 
                      information. Two modules are presented to enhance the mapping 
                      efficiency and label consistency: (1) an inter-submaps label fusion 
                      strategy to eliminate duplicate points across submaps and (2) a 
                      conditional random field (CRF) based approach to enhance panoptic 
                      labels through object label comprehension and contextual information. 
                      We conducted experiments with two public datasets including indoor 
                      and outdoor scenarios. Our system performs comparably to 
                      state-of-the-art (SOTA) methods across geometry and label accuracy 
                      evaluation metrics. The experiment results highlight the 
                      effectiveness and scalability of our system, as it is capable of 
                      constructing precise geometry and maintaining consistent panoptic 
                      labels. Our code is publicly available at 
                      https://github.com/hutslib/DHP-Mapping.
                    </p>
                  </div>
                </div>
              </div>
          </li>



          <li>
            <div class="row">
  <!-- <div class="col-sm-2 abbr">
    <abbr class="badge">dq-gat</abbr>  
  </div> -->
              <div class="col-sm-3">
              
                <img class="img-fluid" src="/IR-STP/intro_overview.png" />
              
              </div>

              <div id="IR-STP" class="col-sm-8">
                
                <div class="title">IR-STP: Enhancing Autonomous Driving With Interaction Reasoning in Spatio-Temporal Planning</div>
                  <div class="author">
                        Yingbing Chen,
                        Jie Cheng,
                        Lu Gan,
                        Sheng Wang,
                    <em>Hongji Liu</em>,
                        Xiaodong Mei,
                        and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium"
                          target="_blank">Ming Liu</a>
                    
                  
                  </div>

                  <div class="periodical">
                    <em>IEEE Transactions on Intelligent Transportation Systems (T-ITS)</em>
                        , 2024
                  </div>
            

                  <div class="links">
                    <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>        
                    <a href="https://ieeexplore.ieee.org/abstract/document/10433826" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">PDF</a>
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Cite</a> -->
                    <!-- <a href="/dq-gat" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Website</a> -->
                  </div>

                  <!-- Hidden abstract block -->
                  
                  <div class="abstract hidden">
                    <p>Considerable research efforts have been devoted to the development 
                      of motion planning algorithms, which form a cornerstone of the 
                      autonomous 
                      driving system (ADS). Nonetheless, acquiring an interactive and 
                      secure trajectory for the ADS remains challenging due to the 
                      complex nature of interaction modeling in planning. Modern 
                      planning methods still employ a uniform treatment of prediction 
                      outcomes and solely rely on collision-avoidance strategies, 
                      leading to suboptimal planning performance. To address this 
                      limitation, this paper presents a novel prediction-based 
                      interactive planning framework for autonomous driving. Our 
                      method incorporates interaction reasoning into spatio-temporal 
                      (s-t) planning by defining interaction conditions and constraints. 
                      Specifically, it records and continually updates interaction 
                      relations for each planned state throughout the forward search. 
                      We assess the performance of our approach alongside 
                      state-of-the-art methods in the CommonRoad environment. 
                      Our experiments include a total of 232 scenarios, with variations 
                      in the accuracy of prediction outcomes, modality, and degrees of 
                      planner aggressiveness. The experimental findings demonstrate the 
                      effectiveness and robustness of our method. It leads to a 
                      reduction of collision times by approximately 17.6% in 3-modal 
                      scenarios, along with improvements of nearly 7.6% in distance 
                      completeness and 31.7% in the fail rate in single-modal scenarios. 
                      For the community‚Äôs reference, our code is accessible at 
                      https://github.com/ChenYingbing/IR-STP-Planner.
                    </p>
                  </div>
                </div>
              </div>
          </li>



          <li>
            <div class="row">
  <!-- <div class="col-sm-2 abbr">
    <abbr class="badge">dq-gat</abbr>  
  </div> -->
              <div class="col-sm-3">
              
                <img class="img-fluid" src="/Snow-Lion/intro_front.png" />
              
              </div>

              <div id="Snow-Lion" class="col-sm-8">
                
                <div class="title">Enhancing Campus Mobility: Achievements and Challenges of Autonomous Shuttle ‚ÄúSnow Lion‚Äù</div>
                  <div class="author">
                        Yingbing Chen,
                        Jie Cheng,
                        Sheng Wang,
                    <em>Hongji Liu</em>,
                        Xiaodong Mei,
                        Xiaoyang Yan,
                        Mingkai Tang,
                        Ge Sun,
                        Ya Wen,
                        Junwei Cai,
                        Xupeng Xie,
                        Lu Gan,
                        Mandan Chao,
                        Ren Xin,
                        <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium"
                          target="_blank">Ming Liu</a>,
                        <a href="https://gogojjh.github.io/"
                          target="_blank">Jianhao Jiao</a>,
                        and Lujia Wang

                  
                  </div>

                  <div class="periodical">
                    <em>Under Review</em>
                        , 2024
                  </div>
            

                  <div class="links">
                    <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>        
                    <a href="https://arxiv.org/html/2401.08939v1" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">PDF</a>
                    <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Cite</a> -->
                    <!-- <a href="/dq-gat" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Website</a> -->
                  </div>

                  <!-- Hidden abstract block -->
                  
                  <div class="abstract hidden">
                    <p>The rapid evolution of autonomous vehicles (AVs) has 
                      significantly influenced global transportation systems. 
                      In this context, we present ``Snow Lion'', an autonomous 
                      shuttle meticulously designed to revolutionize on-campus 
                      transportation, offering a safer and more efficient mobility 
                      solution for students, faculty, and visitors. The primary 
                      objective of this research is to enhance campus mobility by 
                      providing a reliable, efficient, and eco-friendly transportation 
                      solution that seamlessly integrates with existing infrastructure 
                      and meets the diverse needs of a university setting. To achieve 
                      this goal, we delve into the intricacies of the system design, 
                      encompassing sensing, perception, localization, planning, and 
                      control aspects. We evaluate the autonomous shuttle's performance 
                      in real-world scenarios, involving a 1146-kilometer road haul 
                      and the transportation of 442 passengers over a two-month period. 
                      These experiments demonstrate the effectiveness of our system and 
                      offer valuable insights into the intricate process of integrating 
                      an autonomous vehicle within campus shuttle operations. 
                      Furthermore, a thorough analysis of the lessons derived from this 
                      experience furnishes a valuable real-world case study, accompanied 
                      by recommendations for future research and development in the 
                      field of autonomous driving.
                    </p>
                  </div>
                </div>
              </div>
          </li>
      </ol>

        <h2 class="year">2022</h2>
        <ol class="bibliography">
          <li>
              <div class="row">
                <div class="col-sm-3">
                  <img class="img-fluid" src="/360ST-Mapping/pics/teaser.png">
                </div>
                <div id="360ST-Mapping" class="col-sm-8">
              
                  <div class="title">360ST-Mapping: An Online Semantics-Guided Topological Mapping Module for Omnidirectional Visual SLAM</div>
                  <div class="author">
                    <em>Hongji Liu</em>,
                    <a href="https://huajianup.github.io/" target="_blank">Huajian Huang</a>,
                    <a href="https://www.saikit.org/" target="_blank">Sai-Kit Yeung</a>,
                  
                    and <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium" target="_blank">Ming Liu</a>
                  </div>

                  <div class="periodical">
                    <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS‚Äã)</em>
                    , 2022
                  </div>
              

                  <div class="links">
              
                  <a class="abstract badge grey waves-effect font-weight-light mr-1" role="button">Abs</a>
              
                  <a href="https://ieeexplore.ieee.org/document/9982142" class="badge grey waves-effect font-weight-light mr-1"
                   role="button" target="_blank">PDF</a>
                    
                  <!-- <a href="/assets/bibliography/dq-gat.txt" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Cite</a> -->
                  
                  <a href="/360ST-Mapping" class="badge grey waves-effect font-weight-light mr-1" role="button" target="_blank">Website</a>
                
                  </div>
                  
                  <div class="abstract hidden">
                    <p>Topological map as an abstract representation of the observed environment has the advantage in path planning
                       and navigation. Here we proposed an online topological mapping method, 360ST-Mapping, by making use of 
                       omnidirectional vision. The 360¬∞ field of view allows the agent to obtain consistent observation and incrementally
                        extract topological environment information. Moreover, we leverage semantic information to guide topological
                         places recognition further improving performance. The topological map possessing semantic information has the
                          potential to support semantics-related advanced tasks. After combining the topological mapping module with the 
                          omnidirectional visual SLAM, we conduct extensive experiments in several large-scale indoor scenes to validate 
                          the effectiveness.</p>
                  </div>
                </div>
              </div>
            </li>
        </ol> 


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Hongji  Liu.
    Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: April 14, 2024.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
